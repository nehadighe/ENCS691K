"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.S3 = void 0;
const aws_js_1 = __importDefault(require("./aws.js"));
const lodash_1 = __importDefault(require("lodash"));
const providerName = require('../constants').ProviderName;
const configuration_manager_1 = __importDefault(require("../configuration-manager"));
const fs_extra_1 = __importDefault(require("fs-extra"));
const ora_1 = __importDefault(require("ora"));
const paged_call_1 = require("./paged-call");
const minChunkSize = 5 * 1024 * 1024;
class S3 {
    constructor(context, cred, options = {}) {
        this.context = context;
        this.s3 = new aws_js_1.default.S3({ ...cred, ...options });
    }
    static async getInstance(context, options = {}) {
        if (!S3.instance) {
            let cred = {};
            try {
                cred = await configuration_manager_1.default.loadConfiguration(context);
            }
            catch (e) {
            }
            S3.instance = new S3(context, cred, options);
        }
        return S3.instance;
    }
    populateUploadState() {
        const projectDetails = this.context.amplify.getProjectDetails();
        const { envName } = this.context.amplify.getEnvInfo();
        const projectBucket = projectDetails.amplifyMeta.providers
            ? projectDetails.amplifyMeta.providers[providerName].DeploymentBucketName
            : projectDetails.teamProviderInfo[envName][providerName].DeploymentBucketName;
        this.uploadState = {
            envName,
            s3Params: {
                Bucket: projectBucket,
            },
        };
    }
    async uploadFile(s3Params, showSpinner = true) {
        if (this.uploadState === undefined) {
            this.populateUploadState();
        }
        let spinner = showSpinner ? ora_1.default('Uploading files...') : undefined;
        const augmentedS3Params = {
            ...s3Params,
            ...this.uploadState.s3Params,
        };
        let uploadTask;
        try {
            showSpinner && spinner.start('Uploading files...');
            if ((s3Params.Body instanceof fs_extra_1.default.ReadStream && fs_extra_1.default.statSync(s3Params.Body.path).size > minChunkSize) ||
                (Buffer.isBuffer(s3Params.Body) && s3Params.Body.length > minChunkSize)) {
                uploadTask = this.s3.upload(augmentedS3Params);
                uploadTask.on('httpUploadProgress', max => {
                    if (showSpinner)
                        spinner.text = `Uploading Files...${Math.round((max.loaded / max.total) * 100)}%`;
                });
            }
            else {
                uploadTask = this.s3.putObject(augmentedS3Params);
            }
            await uploadTask.promise();
            return this.uploadState.s3Params.Bucket;
        }
        finally {
            showSpinner && spinner.stop();
        }
    }
    async getFile(s3Params, envName = this.context.amplify.getEnvInfo().envName) {
        const projectDetails = this.context.amplify.getProjectDetails();
        const projectBucket = projectDetails.teamProviderInfo[envName][providerName].DeploymentBucketName;
        s3Params.Bucket = projectBucket;
        const result = await this.s3.getObject(s3Params).promise();
        return result.Body;
    }
    async createBucket(bucketName, throwIfExists = false) {
        const params = {
            Bucket: bucketName,
        };
        if (!(await this.ifBucketExists(bucketName))) {
            this.context.print.warning('The specified S3 bucket to store the CloudFormation templates is not present. We are creating one for you....');
            this.context.print.warning(`Bucket name: ${bucketName}`);
            await this.s3.createBucket(params).promise();
            await this.s3.waitFor('bucketExists', params).promise();
            this.context.print.success('S3 bucket successfully created');
            return bucketName;
        }
        else if (throwIfExists) {
            throw new Error(`Bucket ${bucketName} already exists`);
        }
    }
    async getAllObjectKeys(bucketName, continuationToken = null) {
        const result = await paged_call_1.pagedAWSCall(async (param, nextToken) => {
            const parmaWithNextToken = nextToken ? { ...param, ContinuationToken: nextToken } : param;
            return await this.s3.listObjectsV2(parmaWithNextToken).promise();
        }, {
            Bucket: bucketName,
        }, (response) => { var _a; return (_a = response.Contents) === null || _a === void 0 ? void 0 : _a.map(r => ({ Key: r.Key })); }, async (response) => (response && response.IsTruncated ? response.NextContinuationToken : undefined));
        return result;
    }
    async deleteAllObjects(bucketName) {
        const allObjects = await this.getAllObjectKeys(bucketName);
        const chunkedResult = lodash_1.default.chunk(allObjects, 1000);
        for (let chunk of chunkedResult) {
            await this.s3
                .deleteObjects({
                Bucket: bucketName,
                Delete: {
                    Objects: chunk,
                },
            })
                .promise();
        }
    }
    async deleteS3Bucket(bucketName) {
        if (await this.ifBucketExists(bucketName)) {
            await this.deleteAllObjects(bucketName);
            await this.s3.deleteBucket({ Bucket: bucketName }).promise();
        }
    }
    async ifBucketExists(bucketName) {
        try {
            await this.s3
                .headBucket({
                Bucket: bucketName,
            })
                .promise();
            return true;
        }
        catch (e) {
            if (e.statusCode === 404) {
                return false;
            }
            throw e;
        }
    }
}
exports.S3 = S3;
//# sourceMappingURL=aws-s3.js.map